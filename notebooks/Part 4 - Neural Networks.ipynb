{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f0037d",
   "metadata": {},
   "source": [
    "# Advanced Time Series Forecasting for Retail: A Comparative Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66787aa2",
   "metadata": {},
   "source": [
    "# Author: Amina Abacon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed3010c",
   "metadata": {},
   "source": [
    "# Part 4: Neural Networks (No Exogenous Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa27a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 4: NEURAL NETWORKS (NO EXOGENOUS VARIABLES)\n",
      "======================================================================\n",
      "\n",
      "[1] Loading Data...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Loaded data: (109650, 17)\n",
      "Time Series: 150\n",
      "Date Range: 2015-08-16 to 2017-08-15\n"
     ]
    }
   ],
   "source": [
    "# Import data and packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS, NBEATS, PatchTST\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 4: NEURAL NETWORKS (NO EXOGENOUS VARIABLES)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Data\n",
    "# ============================================================================\n",
    "print(\"\\n[1] Loading Data...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "df = pd.read_csv('data/processed/train_with_features.csv', parse_dates=['ds'])\n",
    "\n",
    "print(f\"âœ“ Loaded data: {df.shape}\")\n",
    "print(f\"Time Series: {df['unique_id'].nunique()}\")\n",
    "print(f\"Date Range: {df['ds'].min().date()} to {df['ds'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b0e323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Creating Train/Test Split...\n",
      "----------------------------------------------------------------------\n",
      "Train Set: 2015-08-16 to 2017-08-08\n",
      "  Records: 108,600\n",
      "\n",
      "Test Set: 2017-08-09 to 2017-08-15\n",
      "  Records: 1,050\n",
      "\n",
      "[3] Preparing Data for NeuralForecast...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Training data prepared: (108600, 3)\n",
      "âœ“ Time series: 150\n",
      "âœ“ Average series length: 724 days\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Train/Test Split\n",
    "# ============================================================================\n",
    "print(\"\\n[2] Creating Train/Test Split...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "test_days = 7\n",
    "max_date = df['ds'].max()\n",
    "test_start = max_date - pd.Timedelta(days=test_days - 1)\n",
    "\n",
    "train_df = df[df['ds'] < test_start].copy()\n",
    "test_df = df[df['ds'] >= test_start].copy()\n",
    "\n",
    "print(f\"Train Set: {train_df['ds'].min().date()} to {train_df['ds'].max().date()}\")\n",
    "print(f\"  Records: {len(train_df):,}\")\n",
    "\n",
    "print(f\"\\nTest Set: {test_df['ds'].min().date()} to {test_df['ds'].max().date()}\")\n",
    "print(f\"  Records: {len(test_df):,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Prepare Data for NeuralForecast\n",
    "# ============================================================================\n",
    "print(\"\\n[3] Preparing Data for NeuralForecast...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# NeuralForecast needs: unique_id, ds, y (no exogenous for this part)\n",
    "neural_train = train_df[['unique_id', 'ds', 'y']].copy()\n",
    "neural_train = neural_train.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ“ Training data prepared: {neural_train.shape}\")\n",
    "print(f\"âœ“ Time series: {neural_train['unique_id'].nunique()}\")\n",
    "print(f\"âœ“ Average series length: {len(neural_train) / neural_train['unique_id'].nunique():.0f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5cea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] Initializing Neural Network Models...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Model Configuration:\n",
      "  Forecast Horizon: 7 days\n",
      "  Input Size: 28 days (4 weeks)\n",
      "  Loss Function: MAE\n",
      "  Training Steps: 500\n",
      "  Early Stopping: Enabled (patience=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Models initialized:\n",
      "  1. NHITS - Neural Hierarchical Interpolation (SOTA)\n",
      "  2. NBEATS - Neural Basis Expansion (interpretable)\n",
      "  3. PatchTST - Transformer-based (cutting-edge)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: Initialize Neural Network Models\n",
    "# ============================================================================\n",
    "print(\"\\n[4] Initializing Neural Network Models...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "forecast_horizon = 7\n",
    "input_size = 7 * 4  # 4 weeks of history\n",
    "\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  Forecast Horizon: {forecast_horizon} days\")\n",
    "print(f\"  Input Size: {input_size} days (4 weeks)\")\n",
    "print(f\"  Loss Function: MAE\")\n",
    "print(f\"  Training Steps: 500\")\n",
    "print(f\"  Early Stopping: Enabled (patience=5)\")\n",
    "\n",
    "# Initialize three neural network architectures\n",
    "nhits = NHITS(\n",
    "    h=forecast_horizon,\n",
    "    input_size=input_size,\n",
    "    max_steps=500,\n",
    "    early_stop_patience_steps=5,\n",
    "    loss=MAE(),\n",
    "    scaler_type='robust',\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "nbeats = NBEATS(\n",
    "    h=forecast_horizon,\n",
    "    input_size=input_size,\n",
    "    max_steps=500,\n",
    "    early_stop_patience_steps=5,\n",
    "    loss=MAE(),\n",
    "    scaler_type='robust',\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "patchtst = PatchTST(\n",
    "    h=forecast_horizon,\n",
    "    input_size=input_size,\n",
    "    max_steps=500,\n",
    "    early_stop_patience_steps=5,\n",
    "    scaler_type='robust',\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "models = [nhits, nbeats, patchtst]\n",
    "\n",
    "print(\"\\nâœ“ Models initialized:\")\n",
    "print(\"  1. NHITS - Neural Hierarchical Interpolation (SOTA)\")\n",
    "print(\"  2. NBEATS - Neural Basis Expansion (interpretable)\")\n",
    "print(\"  3. PatchTST - Transformer-based (cutting-edge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54626df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] Training Neural Network Models...\n",
      "----------------------------------------------------------------------\n",
      " Training 3 models on 150 time series...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.771     Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2cc9040a324cf5a638478ae51a85bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.4 M  | train\n",
      "-------------------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "525       Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.769     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5d3a9f1c4d4d669bb5c695763fc10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type              | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss         | MAE               | 0      | train\n",
      "1 | padder_train | ConstantPad1d     | 0      | train\n",
      "2 | scaler       | TemporalNorm      | 0      | train\n",
      "3 | model        | PatchTST_backbone | 402 K  | train\n",
      "-----------------------------------------------------------\n",
      "402 K     Trainable params\n",
      "3         Non-trainable params\n",
      "402 K     Total params\n",
      "1.611     Total estimated model params size (MB)\n",
      "90        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24272464f3dd4eae8de6cc440264e492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Train Models\n",
    "# ============================================================================\n",
    "print(\"\\n[5] Training Neural Network Models...\")\n",
    "print(\"-\" * 70)\n",
    "print(\" Training 3 models on 150 time series...\")\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "# Train with validation set for early stopping\n",
    "nf.fit(df=neural_train, val_size=7)\n",
    "\n",
    "print(\"\\nâœ“ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a665e796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6] Generating Forecasts...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a51c3a51b1549b3a63986756f6cabab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc046807a43a4337b12780129b7e907a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe12a15aee74b52b2d054fa94dad1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Generated forecasts: (1050, 5)\n",
      "\n",
      "Forecast columns: ['unique_id', 'ds', 'NHITS', 'NBEATS', 'PatchTST']\n",
      "\n",
      "Sample forecasts:\n",
      "               unique_id         ds        NHITS       NBEATS     PatchTST\n",
      "0     store_10_BEVERAGES 2017-08-09  1257.434814  1216.687378  1216.624512\n",
      "1     store_10_BEVERAGES 2017-08-10  1317.754761  1314.281982  1322.969238\n",
      "2     store_10_BEVERAGES 2017-08-11  1399.203125  1405.639893  1412.879639\n",
      "3     store_10_BEVERAGES 2017-08-12  1623.655273  1588.416992  1551.081421\n",
      "4     store_10_BEVERAGES 2017-08-13  1591.757080  1526.232910  1535.395142\n",
      "5     store_10_BEVERAGES 2017-08-14  1381.227905  1275.457153  1337.587402\n",
      "6     store_10_BEVERAGES 2017-08-15  1510.223511  1392.361938  1489.016846\n",
      "7  store_10_BREAD/BAKERY 2017-08-09   106.862144   106.374527   109.562126\n",
      "8  store_10_BREAD/BAKERY 2017-08-10    99.230827    96.138901   101.607796\n",
      "9  store_10_BREAD/BAKERY 2017-08-11    85.934875    82.451080    90.954803\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Generate Forecasts\n",
    "# ============================================================================\n",
    "print(\"\\n[6] Generating Forecasts...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "forecasts = nf.predict()\n",
    "\n",
    "print(f\"âœ“ Generated forecasts: {forecasts.shape}\")\n",
    "print(f\"\\nForecast columns: {forecasts.columns.tolist()}\")\n",
    "print(f\"\\nSample forecasts:\")\n",
    "print(forecasts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff68b716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7] Evaluating Model Performance...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Merged evaluation data: (1050, 7)\n",
      "\n",
      " Neural Network Performance:\n",
      "   Model           Type        MAE       RMSE      MAPE\n",
      "PatchTST Neural Network 213.834889 465.574524 16.971101\n",
      "  NBEATS Neural Network 217.471313 465.096432 16.894965\n",
      "   NHITS Neural Network 225.062459 476.347403 17.365082\n",
      "\n",
      " Best Neural Network: PatchTST\n",
      "   MAE: $213.83\n",
      "   RMSE: $465.57\n",
      "   MAPE: 16.97%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Evaluate Performance\n",
    "# ============================================================================\n",
    "print(\"\\n[7] Evaluating Model Performance...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Merge forecasts with actuals\n",
    "forecasts_df = forecasts.reset_index()\n",
    "\n",
    "eval_df = test_df[['unique_id', 'ds', 'y']].merge(\n",
    "    forecasts_df,\n",
    "    on=['unique_id', 'ds'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Merged evaluation data: {eval_df.shape}\")\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    \"\"\"Calculate forecasting error metrics\"\"\"\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    mask = ~(np.isnan(actual) | np.isnan(predicted))\n",
    "    actual = actual[mask]\n",
    "    predicted = predicted[mask]\n",
    "    \n",
    "    if len(actual) == 0:\n",
    "        return {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "    \n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "    rmse = np.sqrt(np.mean((actual - predicted) ** 2))\n",
    "    mape = np.mean(np.abs((actual - predicted) / (actual + 1e-10))) * 100\n",
    "    \n",
    "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
    "\n",
    "# Calculate metrics for each model\n",
    "model_names = ['NHITS', 'NBEATS', 'PatchTST']\n",
    "results = []\n",
    "\n",
    "for model in model_names:\n",
    "    if model in eval_df.columns:\n",
    "        metrics = calculate_metrics(eval_df['y'], eval_df[model])\n",
    "        metrics['Model'] = model\n",
    "        metrics['Type'] = 'Neural Network'\n",
    "        results.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[['Model', 'Type', 'MAE', 'RMSE', 'MAPE']].sort_values('MAE')\n",
    "\n",
    "print(\"\\n Neural Network Performance:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_neural = results_df.iloc[0]\n",
    "print(f\"\\n Best Neural Network: {best_neural['Model']}\")\n",
    "print(f\"   MAE: ${best_neural['MAE']:.2f}\")\n",
    "print(f\"   RMSE: ${best_neural['RMSE']:.2f}\")\n",
    "print(f\"   MAPE: {best_neural['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409f223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8] Comparing with Statistical Baseline...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Best Statistical Model: AutoTheta\n",
      "  MAE: $276.44\n",
      "\n",
      "Best Neural Network: PatchTST\n",
      "  MAE: $213.83\n",
      "\n",
      "ðŸŽ‰ Neural Networks vs Statistical:\n",
      "  Improvement: +22.6%\n",
      "  Neural networks show significant improvement!\n"
     ]
    }
   ],
   "source": [
    "#============================================================================\n",
    "# STEP 8: Compare with Statistical Baseline\n",
    "# ============================================================================\n",
    "print(\"\\n[8] Comparing with Statistical Baseline...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Load baseline results\n",
    "baseline_results = pd.read_csv('output/baseline_results.csv')\n",
    "best_statistical = baseline_results.iloc[0]\n",
    "\n",
    "print(f\"\\nBest Statistical Model: {best_statistical['Model']}\")\n",
    "print(f\"  MAE: ${best_statistical['MAE']:.2f}\")\n",
    "\n",
    "print(f\"\\nBest Neural Network: {best_neural['Model']}\")\n",
    "print(f\"  MAE: ${best_neural['MAE']:.2f}\")\n",
    "\n",
    "improvement = ((best_statistical['MAE'] - best_neural['MAE']) / best_statistical['MAE']) * 100\n",
    "\n",
    "print(f\"\\n{'ðŸŽ‰' if improvement > 0 else 'âš ï¸'} Neural Networks vs Statistical:\")\n",
    "print(f\"  Improvement: {improvement:+.1f}%\")\n",
    "\n",
    "if improvement > 10:\n",
    "    print(\"  Neural networks show significant improvement!\")\n",
    "elif improvement > 0:\n",
    "    print(\"  âœ“ Neural networks show modest improvement\")\n",
    "else:\n",
    "    print(\"   Statistical models remain competitive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90cbfb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[9] Saving Results...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Saved: output\\neural_eval_checkpoint.csv\n",
      "âœ“ Saved: output\\neural_results.csv\n",
      "âœ“ Saved: output\\neural_forecasts.csv\n",
      "\n",
      "  RECOMMENDED: Restart kernel now to free memory\n",
      "   Then run Part 4B (analysis notebook)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: Save Results (Checkpoint)\n",
    "# ============================================================================\n",
    "print(\"\\n[9] Saving Results...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "output_path = Path('output')\n",
    "\n",
    "# Save evaluation data\n",
    "eval_df.to_csv(output_path / 'neural_eval_checkpoint.csv', index=False)\n",
    "print(f\"âœ“ Saved: {output_path / 'neural_eval_checkpoint.csv'}\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(output_path / 'neural_results.csv', index=False)\n",
    "print(f\"âœ“ Saved: {output_path / 'neural_results.csv'}\")\n",
    "\n",
    "# Save forecasts\n",
    "forecasts.to_csv(output_path / 'neural_forecasts.csv')\n",
    "print(f\"âœ“ Saved: {output_path / 'neural_forecasts.csv'}\")\n",
    "\n",
    "print(\"\\n  RECOMMENDED: Restart kernel now to free memory\")\n",
    "print(\"   Then run Part 4B (analysis notebook)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcaa8c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NEURAL NETWORK TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      " Results Summary:\n",
      "  Models Trained: 3\n",
      "  Best Model: PatchTST\n",
      "  MAE: $213.83\n",
      "  Improvement vs Baseline: +22.6%\n",
      "\n",
      " Checkpoint Files Saved:\n",
      "  - neural_eval_checkpoint.csv\n",
      "  - neural_results.csv\n",
      "  - neural_forecasts.csv\n",
      "\n",
      " Next Steps:\n",
      "  1. Restart kernel (Kernel â†’ Restart)\n",
      "  2. Run Part 4B - Neural Network Analysis\n",
      "  3. Create visualizations and detailed comparison\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NEURAL NETWORK TRAINING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n Results Summary:\")\n",
    "print(f\"  Models Trained: {len(model_names)}\")\n",
    "print(f\"  Best Model: {best_neural['Model']}\")\n",
    "print(f\"  MAE: ${best_neural['MAE']:.2f}\")\n",
    "print(f\"  Improvement vs Baseline: {improvement:+.1f}%\")\n",
    "\n",
    "print(f\"\\n Checkpoint Files Saved:\")\n",
    "print(f\"  - neural_eval_checkpoint.csv\")\n",
    "print(f\"  - neural_results.csv\")\n",
    "print(f\"  - neural_forecasts.csv\")\n",
    "\n",
    "print(f\"\\n Next Steps:\")\n",
    "print(f\"  1. Restart kernel (Kernel â†’ Restart)\")\n",
    "print(f\"  2. Run Part 4B - Neural Network Analysis\")\n",
    "print(f\"  3. Create visualizations and detailed comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732b03b",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
