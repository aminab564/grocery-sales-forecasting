{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1775fd",
   "metadata": {},
   "source": [
    "# Advanced Time Series Forecasting for Retail: A Comparative Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d44b5",
   "metadata": {},
   "source": [
    "# Author: Amina Abacon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eea683",
   "metadata": {},
   "source": [
    "# Part 5: Neural Networks WITH Exogenous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd57e678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PART 5: NEURAL NETWORKS WITH EXOGENOUS VARIABLES\n",
      "======================================================================\n",
      "\n",
      "[1] Loading Data with Features...\n",
      "----------------------------------------------------------------------\n",
      "✓ Loaded data: (109650, 17)\n",
      "Time Series: 150\n",
      "Date Range: 2015-08-16 to 2017-08-15\n",
      "\n",
      "Exogenous Features (9):\n",
      "  1. has_promotion\n",
      "  2. dcoilwtico\n",
      "  3. oil_ma7\n",
      "  4. is_holiday\n",
      "  5. is_weekend\n",
      "  6. month\n",
      "  7. dayofweek\n",
      "  8. is_month_start\n",
      "  9. is_month_end\n"
     ]
    }
   ],
   "source": [
    "# Import data and packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import PatchTST\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.models import (\n",
    "    NHITS,\n",
    "    TFT,           \n",
    "    TimesNet,     \n",
    ")\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PART 5: NEURAL NETWORKS WITH EXOGENOUS VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Data with Features\n",
    "# ============================================================================\n",
    "print(\"\\n[1] Loading Data with Features...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "df = pd.read_csv('data/processed/train_with_features.csv', parse_dates=['ds'])\n",
    "\n",
    "print(f\"✓ Loaded data: {df.shape}\")\n",
    "print(f\"Time Series: {df['unique_id'].nunique()}\")\n",
    "print(f\"Date Range: {df['ds'].min().date()} to {df['ds'].max().date()}\")\n",
    "\n",
    "# Load feature configuration\n",
    "import json\n",
    "with open('data/processed/feature_config.json', 'r') as f:\n",
    "    feature_config = json.load(f)\n",
    "\n",
    "EXOG_FEATURES = feature_config['exogenous_features']\n",
    "print(f\"\\nExogenous Features ({len(EXOG_FEATURES)}):\")\n",
    "for i, feat in enumerate(EXOG_FEATURES, 1):\n",
    "    print(f\"  {i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d138d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Creating Train/Test Split...\n",
      "----------------------------------------------------------------------\n",
      "Train Set: 2015-08-16 to 2017-08-08\n",
      "  Records: 108,600\n",
      "\n",
      "Test Set: 2017-08-09 to 2017-08-15\n",
      "  Records: 1,050\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Train/Test Split\n",
    "# ============================================================================\n",
    "print(\"\\n[2] Creating Train/Test Split...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "test_days = 7\n",
    "max_date = df['ds'].max()\n",
    "test_start = max_date - pd.Timedelta(days=test_days - 1)\n",
    "\n",
    "train_df = df[df['ds'] < test_start].copy()\n",
    "test_df = df[df['ds'] >= test_start].copy()\n",
    "\n",
    "print(f\"Train Set: {train_df['ds'].min().date()} to {train_df['ds'].max().date()}\")\n",
    "print(f\"  Records: {len(train_df):,}\")\n",
    "\n",
    "print(f\"\\nTest Set: {test_df['ds'].min().date()} to {test_df['ds'].max().date()}\")\n",
    "print(f\"  Records: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3334651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] Preparing Data with Exogenous Features...\n",
      "----------------------------------------------------------------------\n",
      "✓ Training data: (108600, 12)\n",
      "✓ Future exogenous: (1050, 11)\n",
      "✓ No missing values in exogenous features\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Prepare Data with Exogenous Features\n",
    "# ============================================================================\n",
    "print(\"\\n[3] Preparing Data with Exogenous Features...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Training data with exogenous\n",
    "train_cols = ['unique_id', 'ds', 'y'] + EXOG_FEATURES\n",
    "neural_train = train_df[train_cols].copy()\n",
    "neural_train = neural_train.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "# Future exogenous (test period features)\n",
    "future_exog = test_df[['unique_id', 'ds'] + EXOG_FEATURES].copy()\n",
    "future_exog = future_exog.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Training data: {neural_train.shape}\")\n",
    "print(f\"✓ Future exogenous: {future_exog.shape}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_train = neural_train[EXOG_FEATURES].isnull().sum().sum()\n",
    "missing_future = future_exog[EXOG_FEATURES].isnull().sum().sum()\n",
    "\n",
    "if missing_train > 0 or missing_future > 0:\n",
    "    print(f\"\\n  Missing values: train={missing_train}, future={missing_future}\")\n",
    "else:\n",
    "    print(\"✓ No missing values in exogenous features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc643e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Initializing Models with Exogenous Features...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Model Configuration:\n",
      "  Forecast Horizon: 7 days\n",
      "  Input Size: 28 days\n",
      "  Exogenous Features: 9\n",
      "  Loss Function: MAE\n",
      "  Training Steps: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: Initialize Models with Exogenous Features\n",
    "# ============================================================================\n",
    "\n",
    "# Define forecast configuration\n",
    "forecast_horizon = 7  # 7-day forecast\n",
    "input_size = 28       # Use 28 days of history\n",
    "\n",
    "print(\"[4] Initializing Models with Exogenous Features...\")\n",
    "print(\"-\" * 70)\n",
    "print(\"\\nModel Configuration:\")\n",
    "print(f\"  Forecast Horizon: {forecast_horizon} days\")\n",
    "print(f\"  Input Size: {input_size} days\")\n",
    "print(f\"  Exogenous Features: {len(EXOG_FEATURES)}\")\n",
    "print(f\"  Loss Function: MAE\")\n",
    "print(f\"  Training Steps: 500\")\n",
    "\n",
    "# Use NHITS with different configurations\n",
    "nhits_base = NHITS(\n",
    "    h=forecast_horizon,\n",
    "    input_size=input_size,\n",
    "    futr_exog_list=EXOG_FEATURES,\n",
    "    max_steps=500,\n",
    "    early_stop_patience_steps=5,\n",
    "    scaler_type='robust',\n",
    "    random_seed=42,\n",
    "    alias='NHITS_base'\n",
    ")\n",
    "\n",
    "nhits_deep = NHITS(\n",
    "    h=forecast_horizon,\n",
    "    input_size=input_size,\n",
    "    futr_exog_list=EXOG_FEATURES,\n",
    "    max_steps=500,\n",
    "    early_stop_patience_steps=5,\n",
    "    scaler_type='robust',\n",
    "    random_seed=42,\n",
    "    n_pool_kernel_size=[2, 2, 2],\n",
    "    alias='NHITS_deep'\n",
    ")\n",
    "\n",
    "models = [nhits_base, nhits_deep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9514081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] Training Models with Exogenous Variables...\n",
      "----------------------------------------------------------------------\n",
      " Training 2 models on 150 time series with 9 features...\n",
      "   Estimated time: 8-12 minutes (CPU) or 3-5 minutes (GPU)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.8 M  | train\n",
      "-------------------------------------------------------\n",
      "2.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 M     Total params\n",
      "11.080    Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e243e7021752426a96ca0e314e3805b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | blocks       | ModuleList    | 2.7 M  | train\n",
      "-------------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 M     Total params\n",
      "10.738    Total estimated model params size (MB)\n",
      "34        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a6464f1a6d4a38a18d3c9a16391721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Training complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Train Models\n",
    "# ============================================================================\n",
    "print(\"\\n[5] Training Models with Exogenous Variables...\")\n",
    "print(\"-\" * 70)\n",
    "print(\" Training 2 models on 150 time series with 9 features...\")\n",
    "print(\"   Estimated time: 8-12 minutes (CPU) or 3-5 minutes (GPU)\\n\")\n",
    "\n",
    "nf = NeuralForecast(models=models, freq='D')\n",
    "\n",
    "# Train with validation set\n",
    "nf.fit(df=neural_train, val_size=7)\n",
    "\n",
    "print(\"\\n✓ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684038e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6] Generating Forecasts with Future Exogenous...\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a627030d442147b3b49c9575876ec16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106a16b425904931901db3cf93cdb7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated forecasts: (1050, 4)\n",
      "\n",
      "Forecast columns: ['unique_id', 'ds', 'NHITS_base', 'NHITS_deep']\n",
      "\n",
      "Sample forecasts:\n",
      "               unique_id         ds   NHITS_base   NHITS_deep\n",
      "0     store_10_BEVERAGES 2017-08-09  1111.021606  1154.508301\n",
      "1     store_10_BEVERAGES 2017-08-10  1253.534180  1176.073486\n",
      "2     store_10_BEVERAGES 2017-08-11  1324.482300  1355.609619\n",
      "3     store_10_BEVERAGES 2017-08-12  1562.751343  1566.406372\n",
      "4     store_10_BEVERAGES 2017-08-13  1486.057251  1478.462280\n",
      "5     store_10_BEVERAGES 2017-08-14  1224.601929  1246.021118\n",
      "6     store_10_BEVERAGES 2017-08-15  1464.591431  1400.602905\n",
      "7  store_10_BREAD/BAKERY 2017-08-09    95.368370   102.760956\n",
      "8  store_10_BREAD/BAKERY 2017-08-10    93.047325    96.740891\n",
      "9  store_10_BREAD/BAKERY 2017-08-11    87.632378    91.555168\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Generate Forecasts with Future Exogenous\n",
    "# ============================================================================\n",
    "print(\"\\n[6] Generating Forecasts with Future Exogenous...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# CRITICAL: Pass future exogenous features\n",
    "forecasts = nf.predict(futr_df=future_exog)\n",
    "\n",
    "print(f\"✓ Generated forecasts: {forecasts.shape}\")\n",
    "print(f\"\\nForecast columns: {forecasts.columns.tolist()}\")\n",
    "print(f\"\\nSample forecasts:\")\n",
    "print(forecasts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f4f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7] Evaluating Model Performance...\n",
      "----------------------------------------------------------------------\n",
      "✓ Merged evaluation data: (1050, 6)\n",
      "\n",
      " Neural Network + Exogenous Performance:\n",
      "            Model           Type        MAE       RMSE      MAPE\n",
      "NHITS_base + Exog Neural Network 204.074263 442.010958 15.874679\n",
      "NHITS_deep + Exog Neural Network 212.775158 444.583458 16.571112\n",
      "\n",
      " Best Model with Exogenous: NHITS_base + Exog\n",
      "   MAE: 204.07\n",
      "   RMSE: 442.01\n",
      "   MAPE: 15.87%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Evaluate Performance\n",
    "# ============================================================================\n",
    "print(\"\\n[7] Evaluating Model Performance...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Merge forecasts with actuals\n",
    "forecasts_df = forecasts.reset_index()\n",
    "\n",
    "eval_df = test_df[['unique_id', 'ds', 'y']].merge(\n",
    "    forecasts_df,\n",
    "    on=['unique_id', 'ds'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"✓ Merged evaluation data: {eval_df.shape}\")\n",
    "\n",
    "def calculate_metrics(actual, predicted):\n",
    "    \"\"\"Calculate forecasting error metrics\"\"\"\n",
    "    actual = np.array(actual)\n",
    "    predicted = np.array(predicted)\n",
    "    \n",
    "    mask = ~(np.isnan(actual) | np.isnan(predicted))\n",
    "    actual = actual[mask]\n",
    "    predicted = predicted[mask]\n",
    "    \n",
    "    if len(actual) == 0:\n",
    "        return {'MAE': np.nan, 'RMSE': np.nan, 'MAPE': np.nan}\n",
    "    \n",
    "    mae = np.mean(np.abs(actual - predicted))\n",
    "    rmse = np.sqrt(np.mean((actual - predicted) ** 2))\n",
    "    mape = np.mean(np.abs((actual - predicted) / (actual + 1e-10))) * 100\n",
    "    \n",
    "    return {'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
    "\n",
    "# Calculate metrics for each model\n",
    "model_cols = [col for col in eval_df.columns if col in ['NHITS_base', 'NHITS_deep']]\n",
    "results = []\n",
    "\n",
    "for model in model_cols:\n",
    "    metrics = calculate_metrics(eval_df['y'], eval_df[model])\n",
    "    metrics['Model'] = model + ' + Exog'\n",
    "    metrics['Type'] = 'Neural Network'\n",
    "    results.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df[['Model', 'Type', 'MAE', 'RMSE', 'MAPE']].sort_values('MAE')\n",
    "\n",
    "print(\"\\n Neural Network + Exogenous Performance:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_with_exog = results_df.iloc[0]\n",
    "print(f\"\\n Best Model with Exogenous: {best_with_exog['Model']}\")\n",
    "print(f\"   MAE: {best_with_exog['MAE']:.2f}\")\n",
    "print(f\"   RMSE: {best_with_exog['RMSE']:.2f}\")\n",
    "print(f\"   MAPE: {best_with_exog['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7021b992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8] Comparing with Previous Results...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Best Statistical: AutoTheta\n",
      "  MAE: 276.44\n",
      "\n",
      "Best Neural (no exog): PatchTST\n",
      "  MAE: 213.83\n",
      "\n",
      "Best Neural (with exog): NHITS_base + Exog\n",
      "  MAE: 204.07\n",
      "\n",
      " Improvements:\n",
      "  vs. Statistical Baseline: +26.2%\n",
      "  vs. Neural (no exog): +4.6%\n",
      "\n",
      " Exogenous features significantly improved neural networks!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: Compare with Previous Results\n",
    "# ============================================================================\n",
    "print(\"\\n[8] Comparing with Previous Results...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Load Part 4 results (neural without exogenous)\n",
    "neural_no_exog = pd.read_csv('output/neural_results.csv')\n",
    "best_no_exog = neural_no_exog.iloc[0]\n",
    "\n",
    "# Load baseline (statistical)\n",
    "baseline = pd.read_csv('output/baseline_results.csv')\n",
    "best_statistical = baseline.iloc[0]\n",
    "\n",
    "print(f\"\\nBest Statistical: {best_statistical['Model']}\")\n",
    "print(f\"  MAE: {best_statistical['MAE']:.2f}\")\n",
    "\n",
    "print(f\"\\nBest Neural (no exog): {best_no_exog['Model']}\")\n",
    "print(f\"  MAE: {best_no_exog['MAE']:.2f}\")\n",
    "\n",
    "print(f\"\\nBest Neural (with exog): {best_with_exog['Model']}\")\n",
    "print(f\"  MAE: {best_with_exog['MAE']:.2f}\")\n",
    "\n",
    "improvement_vs_statistical = ((best_statistical['MAE'] - best_with_exog['MAE']) / best_statistical['MAE']) * 100\n",
    "improvement_vs_neural = ((best_no_exog['MAE'] - best_with_exog['MAE']) / best_no_exog['MAE']) * 100\n",
    "\n",
    "print(f\"\\n Improvements:\")\n",
    "print(f\"  vs. Statistical Baseline: {improvement_vs_statistical:+.1f}%\")\n",
    "print(f\"  vs. Neural (no exog): {improvement_vs_neural:+.1f}%\")\n",
    "\n",
    "if improvement_vs_neural > 2:\n",
    "    print(\"\\n Exogenous features significantly improved neural networks!\")\n",
    "elif improvement_vs_neural > 0:\n",
    "    print(\"\\n✓ Exogenous features provided modest improvement\")\n",
    "else:\n",
    "    print(\"\\n  Exogenous features did not improve neural networks\")\n",
    "    print(\"   Simpler model (no exog) may be preferred for deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d0cc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[9] Saving Results...\n",
      "----------------------------------------------------------------------\n",
      "✓ Saved: output\\neural_exog_eval_checkpoint.csv\n",
      "✓ Saved: output\\neural_exog_results.csv\n",
      "✓ Saved: output\\neural_exog_forecasts.csv\n",
      "\n",
      "  RECOMMENDED: Restart kernel now to free memory\n",
      "   Then run Part 5B (final analysis & decision)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: Save Results (Checkpoint)\n",
    "# ============================================================================\n",
    "print(\"\\n[9] Saving Results...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "output_path = Path('output')\n",
    "\n",
    "# Save evaluation data\n",
    "eval_df.to_csv(output_path / 'neural_exog_eval_checkpoint.csv', index=False)\n",
    "print(f\"✓ Saved: {output_path / 'neural_exog_eval_checkpoint.csv'}\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(output_path / 'neural_exog_results.csv', index=False)\n",
    "print(f\"✓ Saved: {output_path / 'neural_exog_results.csv'}\")\n",
    "\n",
    "# Save forecasts\n",
    "forecasts.to_csv(output_path / 'neural_exog_forecasts.csv')\n",
    "print(f\"✓ Saved: {output_path / 'neural_exog_forecasts.csv'}\")\n",
    "\n",
    "print(\"\\n  RECOMMENDED: Restart kernel now to free memory\")\n",
    "print(\"   Then run Part 5B (final analysis & decision)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df669675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NEURAL NETWORKS + EXOGENOUS TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      " Results Summary:\n",
      "  Best Model: NHITS_base + Exog\n",
      "  MAE: 204.07\n",
      "  Improvement vs Statistical: +26.2%\n",
      "  Improvement vs Neural (no exog): +4.6%\n",
      "\n",
      " Checkpoint Files Saved:\n",
      "  - neural_exog_eval_checkpoint.csv\n",
      "  - neural_exog_results.csv\n",
      "  - neural_exog_forecasts.csv\n",
      "\n",
      " Next Steps:\n",
      "  1. Restart kernel (Kernel → Restart)\n",
      "  2. Run Part 5B - Final Analysis & Model Decision\n",
      "  3. Get final recommendation for capstone\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NEURAL NETWORKS + EXOGENOUS TRAINING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n Results Summary:\")\n",
    "print(f\"  Best Model: {best_with_exog['Model']}\")\n",
    "print(f\"  MAE: {best_with_exog['MAE']:.2f}\")\n",
    "print(f\"  Improvement vs Statistical: {improvement_vs_statistical:+.1f}%\")\n",
    "print(f\"  Improvement vs Neural (no exog): {improvement_vs_neural:+.1f}%\")\n",
    "\n",
    "print(f\"\\n Checkpoint Files Saved:\")\n",
    "print(f\"  - neural_exog_eval_checkpoint.csv\")\n",
    "print(f\"  - neural_exog_results.csv\")\n",
    "print(f\"  - neural_exog_forecasts.csv\")\n",
    "\n",
    "print(f\"\\n Next Steps:\")\n",
    "print(f\"  1. Restart kernel (Kernel → Restart)\")\n",
    "print(f\"  2. Run Part 5B - Final Analysis & Model Decision\")\n",
    "print(f\"  3. Get final recommendation for capstone\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6ef60",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
